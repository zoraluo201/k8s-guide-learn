## 集群突然崩溃（未断电）

排错记录如下。

突现集群失联：

```shell
➜  ~ kk get nodes          
Get "https://192.168.31.2:6443/api/v1/nodes?limit=500": dial tcp 192.168.31.2:6443: connect: connection refused - error from a previous attempt: 
read tcp 192.168.31.2:38988->192.168.31.2:6443: read: connection reset by peer
```

查询master上的kubelet：

```shell
➜  ~ journalctl -u kubelet -f --lines=10
-- Logs begin at Wed 2024-03-13 12:17:57 CST. --
Mar 13 12:33:27 k8s-master kubelet[3317]: E0313 12:33:27.819329    3317 pod_workers.go:1281] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=kube-apiserver pod=kube-apiserver-k8s-master_kube-system(e3a125d02a8ad94eb68b6e23b1be623b)\"" pod="kube-system/kube-apiserver-k8s-master" podUID=e3a125d02a8ad94eb68b6e23b1be623b
Mar 13 12:33:32 k8s-master kubelet[3317]: W0313 12:33:32.011136    3317 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.31.2:6443/api/v1/nodes?fieldSelector=metadata.name%3Dk8s-master&limit=500&resourceVersion=0": dial tcp 192.168.31.2:6443: connect: connection refused
Mar 13 12:33:32 k8s-master kubelet[3317]: E0313 12:33:32.011332    3317 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.31.2:6443/api/v1/nodes?fieldSelector=metadata.name%3Dk8s-master&limit=500&resourceVersion=0": dial tcp 192.168.31.2:6443: connect: connection refused
Mar 13 12:33:32 k8s-master kubelet[3317]: E0313 12:33:32.175514    3317 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"k8s-master.17bc389cd76e61eb", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"k8s-master", UID:"k8s-master", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"InvalidDiskCapacity", Message:"invalid capacity 0 on image filesystem", Source:v1.EventSource{Component:"kubelet", Host:"k8s-master"}, FirstTimestamp:time.Date(2024, time.March, 13, 12, 30, 4, 774334955, time.Local), LastTimestamp:time.Date(2024, time.March, 13, 12, 30, 4, 774334955, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://192.168.31.2:6443/api/v1/namespaces/default/events": dial tcp 192.168.31.2:6443: connect: connection refused'(may retry after sleeping)
Mar 13 12:33:32 k8s-master kubelet[3317]: E0313 12:33:32.260788    3317 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.31.2:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/k8s-master?timeout=10s\": dial tcp 192.168.31.2:6443: connect: connection refused" interval="7s"
Mar 13 12:33:33 k8s-master kubelet[3317]: I0313 12:33:33.821483    3317 scope.go:115] "RemoveContainer" containerID="58709cd211a28546022198f4fb4b03aa5b00d5f3544205c4d3a20bc62beeb697"
Mar 13 12:33:33 k8s-master kubelet[3317]: E0313 12:33:33.821994    3317 pod_workers.go:1281] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"etcd\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=etcd pod=etcd-k8s-master_kube-system(2ff9ff04501d676e64442628983b4835)\"" pod="kube-system/etcd-k8s-master" podUID=2ff9ff04501d676e64442628983b4835
Mar 13 12:33:34 k8s-master kubelet[3317]: I0313 12:33:34.710265    3317 kubelet_node_status.go:70] "Attempting to register node" node="k8s-master"
Mar 13 12:33:34 k8s-master kubelet[3317]: E0313 12:33:34.710782    3317 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://192.168.31.2:6443/api/v1/nodes\": dial tcp 192.168.31.2:6443: connect: connection refused" node="k8s-master"
Mar 13 12:33:34 k8s-master kubelet[3317]: E0313 12:33:34.916998    3317 eviction_manager.go:262] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"k8s-master\" not found"
```

注意关键字：`k8s-master`节点找不到，推测API-SERVER异常。查master上的api-server pod日志：

```shell
➜  ~ crictl ps -a             
CONTAINER           IMAGE               CREATED              STATE               NAME                      ATTEMPT             POD ID              POD
578315b41c9b4       86b6af7dd652c       12 seconds ago       Exited              etcd                      25                  5a363247dae5f       etcd-k8s-master
b2d50227f929d       6f707f569b572       About a minute ago   Exited              kube-apiserver            22                  45d9216986460       kube-apiserver-k8s-master
ec88adec5e028       95fe52ed44570       17 minutes ago       Running             kube-controller-manager   6                   3e32c1cba3e0c       kube-controller-manager-k8s-master
fa510a42f4152       f73f1b39c3fe8       17 minutes ago       Running             kube-scheduler            6                   2a36550ca3f04       kube-scheduler-k8s-master
9768c8e91de17       f73f1b39c3fe8       37 minutes ago       Exited              kube-scheduler            5                   7f8969d06ccb1       kube-scheduler-k8s-master
4745e25865af2       95fe52ed44570       37 minutes ago       Exited              kube-controller-manager   5                   fe47048ef4185       kube-controller-manager-k8s-master
4e441adac932e       8065b798a4d67       About an hour ago    Exited              calico-node               2                   d17987348465a       calico-node-5mhvs
62e5eb82586cc       8065b798a4d67       About an hour ago    Exited              mount-bpffs               0                   d17987348465a       calico-node-5mhvs
43e68a475a785       9dee260ef7f59       About an hour ago    Exited              install-cni               0                   d17987348465a       calico-node-5mhvs
ed250b985206a       9dee260ef7f59       About an hour ago    Exited              upgrade-ipam              2                   d17987348465a       calico-node-5mhvs
8c7321d73e06a       5f82fc39fa816       About an hour ago    Exited              kube-proxy                4                   91c2c551ef4ef       kube-proxy-c9vbt
```

包括`apiserver`在内的多个核心Pod挂掉，查看其日志：

```shell
➜  ~ crictl logs --tail 20 b2d50227f929d
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0313 04:37:50.064278       1 logging.go:59] [core] [Channel #4 SubChannel #6] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0313 04:37:51.531310       1 logging.go:59] [core] [Channel #3 SubChannel #5] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
E0313 04:37:54.265467       1 run.go:74] "command failed" err="context deadline exceeded"
```

2379是etcd端口，也看到了etcd挂掉，查看etcd Pod日志：

```shell
➜  ~ crictl logs --tail 20 578315b41c9b4 
{"level":"info","ts":"2024-03-13T04:35:41.934Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.31.2:2379","--cert-file=/etc/kubernetes/pki/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.31.2:2380","--initial-cluster=k8s-master=https://192.168.31.2:2380","--key-file=/etc/kubernetes/pki/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.31.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.31.2:2380","--name=k8s-master","--peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/etc/kubernetes/pki/etcd/peer.key","--peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt","--snapshot-count=10000","--trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt"]}
{"level":"info","ts":"2024-03-13T04:35:41.934Z","caller":"etcdmain/etcd.go:116","msg":"server has been already initialized","data-dir":"/var/lib/etcd","dir-type":"member"}
{"level":"info","ts":"2024-03-13T04:35:41.934Z","caller":"embed/etcd.go:124","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.31.2:2380"]}
{"level":"info","ts":"2024-03-13T04:35:41.934Z","caller":"embed/etcd.go:484","msg":"starting with peer TLS","tls-info":"cert = /etc/kubernetes/pki/etcd/peer.crt, key = /etc/kubernetes/pki/etcd/peer.key, client-cert=, client-key=, trusted-ca = /etc/kubernetes/pki/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-03-13T04:35:41.934Z","caller":"embed/etcd.go:132","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.31.2:2379"]}
{"level":"info","ts":"2024-03-13T04:35:41.934Z","caller":"embed/etcd.go:306","msg":"starting an etcd server","etcd-version":"3.5.7","git-sha":"215b53cf3","go-version":"go1.17.13","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":true,"name":"k8s-master","data-dir":"/var/lib/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.31.2:2380"],"listen-peer-urls":["https://192.168.31.2:2380"],"advertise-client-urls":["https://192.168.31.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.31.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
panic: freepages: failed to get all reachable pages (page 0: invalid type: meta)

goroutine 123 [running]:
go.etcd.io/bbolt.(*DB).freepages.func2()
        go.etcd.io/bbolt@v1.3.6/db.go:1056 +0x99
created by go.etcd.io/bbolt.(*DB).freepages
        go.etcd.io/bbolt@v1.3.6/db.go:1054 +0x1f6
```

根据日志进行网上查询：https://github.com/etcd-io/etcd/issues/10722 得知是etcd
数据文件损坏了（但我的情况是没有断电也导致这样），要么重装，要么[从备份恢复数据](https://zhuanlan.zhihu.com/p/558940973)。
但笔者没有备份，只能重装！！！